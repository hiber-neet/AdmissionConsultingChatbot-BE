from datetime import datetime
from typing import Any, Dict, List, Optional
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters  import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient, models
from qdrant_client.models import Distance, VectorParams, PointStruct
import os
import uuid
import asyncio
from sqlalchemy.orm import Session
from app.models import schemas
from app.models.entities import AcademicScore, ChatInteraction, ChatSession, DocumentChunk, FaqStatistics, KnowledgeBaseDocument, Major, ParticipateChatSession, RiasecResult, TrainingQuestionAnswer
from app.models.database import SessionLocal
from sqlalchemy.exc import SQLAlchemyError
from app.services.memory_service import MemoryManager
from app.utils.document_processor import DocumentProcessor

memory_service = MemoryManager()

class TrainingService:
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.llm = ChatOpenAI(
            model="gpt-4.1-mini",
            api_key=self.openai_api_key,
            temperature=0.7
        )
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            api_key=self.openai_api_key
        )
        self.qdrant_client = QdrantClient(
            host=os.getenv("QDRANT_HOST", "localhost"),
            port=int(os.getenv("QDRANT_PORT", 6333))
        )
        self.training_qa_collection = "training_qa"
        self.documents_collection = "knowledge_base_documents"
        self._init_collections()

    def _init_collections(self):
        try:
            self.qdrant_client.create_collection(
                collection_name=self.training_qa_collection,
                vectors_config=VectorParams(size=3072, distance=Distance.COSINE)
            )
        except:
            pass
            
        try:
            self.qdrant_client.create_collection(
                collection_name=self.documents_collection,
                vectors_config=VectorParams(size=3072, distance=Distance.COSINE)
            )
        except:
            pass

    def create_chat_session(self, user_id: int, session_type: str = "chatbot") -> int:
        """
        Táº¡o chat session má»›i
        
        Args:
            user_id: ID cá»§a user
            session_type: "chatbot" hoáº·c "live"
        
        Returns:
            session_id: ID cá»§a session vá»«a táº¡o
        """
        
        db = SessionLocal()
        if not user_id:
            session = ChatSession(
                session_type=session_type,
                start_time=datetime.now()
            )
            db.add(session)
            db.flush()
            db.commit()
            return session.chat_session_id
        try:
            session = ChatSession(
                session_type=session_type,
                start_time=datetime.now()
            )
            db.add(session)
            db.flush()
            
            # Add user vÃ o participate table
            participate = ParticipateChatSession(
                user_id=user_id,
                session_id=session.chat_session_id
            )
            db.add(participate)
            db.commit()
            
            return session.chat_session_id
        except SQLAlchemyError as e:
            db.rollback()
            print(f"Error creating session: {e}")
            raise
        finally:
            db.close()

    def get_session_history(self, session_id: int, limit: int = 50) -> List[Dict]:
        """
        Láº¥y lá»‹ch sá»­ chat cá»§a session
        
        Returns:
            List of messages [{message_text, timestamp, is_from_bot}, ...]
        """
        db = SessionLocal()
        try:
            interactions = db.query(ChatInteraction).filter(
                ChatInteraction.session_id == session_id
            ).order_by(
                ChatInteraction.timestamp.asc()
            ).limit(limit).all()
            
            return [
                {
                    "message_text": i.message_text,
                    "timestamp": i.timestamp.isoformat() if i.timestamp else None,
                    "is_from_bot": i.is_from_bot,
                    "rating": i.rating
                }
                for i in interactions
            ]
        finally:
            db.close()
    
    def get_user_sessions(self, user_id: int) -> List[Dict]:
        """
        Láº¥y táº¥t cáº£ sessions cá»§a user (Ä‘á»ƒ hiá»ƒn thá»‹ recent chats)
        
        Returns:
            List of sessions vá»›i preview message cuá»‘i cÃ¹ng
        """
        db = SessionLocal()
        try:
            sessions = db.query(ChatSession).join(
                ParticipateChatSession
            ).filter(
                ParticipateChatSession.user_id == user_id
            ).order_by(
                ChatSession.start_time.desc()
            ).all()
            
            result = []
            for session in sessions:
                # Láº¥y message cuá»‘i cÃ¹ng lÃ m preview
                last_msg = db.query(ChatInteraction).filter(
                    ChatInteraction.session_id == session.chat_session_id
                ).order_by(
                    ChatInteraction.timestamp.desc()
                ).first()
                
                result.append({
                    "session_id": session.chat_session_id,
                    "session_type": session.session_type,
                    "start_time": session.start_time.isoformat() if session.start_time else None,
                    "last_message_preview": last_msg.message_text[:50] + "..." if last_msg else "",
                    "last_message_time": last_msg.timestamp.isoformat() if last_msg and last_msg.timestamp else None
                })
            
            return result
        finally:
            db.close()

    def delete_chat_session(self, session_id: int, user_id: Optional[int] = None) -> bool:
        """
        XÃ³a 1 session chat:
        - Náº¿u cÃ³ user_id: chá»‰ xÃ³a session thuá»™c vá» user Ä‘Ã³
        - Náº¿u khÃ´ng cÃ³ user_id: xÃ³a theo session_id (guest session)

        Tráº£ vá»:
            True  náº¿u xÃ³a Ä‘Æ°á»£c
            False náº¿u khÃ´ng tÃ¬m tháº¥y session
        """
        db = SessionLocal()
        try:
            query = db.query(ChatSession)

            # Náº¿u cÃ³ user_id thÃ¬ check session thuá»™c user Ä‘Ã³
            if user_id:
                query = query.join(ParticipateChatSession).filter(
                    ParticipateChatSession.user_id == user_id
                )

            session = query.filter(
                ChatSession.chat_session_id == session_id
            ).first()

            if not session:
                return False

            # Do ChatSession Ä‘á»‹nh nghÄ©a cascade="all, delete-orphan"
            # nÃªn xÃ³a session sáº½ tá»± xÃ³a ChatInteraction & ParticipateChatSession liÃªn quan
            db.delete(session)
            db.commit()
            return True

        except SQLAlchemyError as e:
            db.rollback()
            print(f"Error deleting session: {e}")
            raise
        finally:
            db.close()

    # ---------------------------
    # Query enrichment: dÃ¹ng chat_history + last bot question Ä‘á»ƒ build a full query
    # ---------------------------
    async def enrich_query(self, session_id: str, user_message: str) -> str:
        memory = memory_service.get_memory(session_id)
        mem_vars = memory.load_memory_variables({})
        chat_history = mem_vars.get("chat_history", "")

        prompt = f"""
        Báº¡n lÃ  má»™t trá»£ lÃ½ giÃºp chuyá»ƒn cÃ¡c cÃ¢u tráº£ lá»i cá»§a ngÆ°á»i dÃ¹ng thÃ nh cÃ¡c truy váº¥n tÃ¬m kiáº¿m Ä‘áº§y Ä‘á»§ cho chatbot RAG tÆ° váº¥n tuyá»ƒn sinh.

        Cuá»™c há»™i thoáº¡i gáº§n Ä‘Ã¢y (theo thá»© tá»± tá»« cÅ© Ä‘áº¿n má»›i):
        {chat_history}

        Pháº£n há»“i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng: "{user_message}"

        Nhiá»‡m vá»¥: Dá»±a trÃªn "cuá»™c há»™i thoáº¡i gáº§n Ä‘Ã¢y" vÃ  "pháº£n há»“i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng", báº¡n hÃ£y Ä‘áº£m báº£o táº¡o ra **má»™t cÃ¢u truy váº¥n tÃ¬m kiáº¿m**, rÃµ rÃ ng, cá»¥ thá»ƒ (báº±ng tiáº¿ng Viá»‡t), thá»ƒ hiá»‡n Ä‘Ãºng Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ gá»­i cho chatbot rag tÆ° váº¥n Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ hiá»ƒu yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng. "Chá»‰ táº¡o truy váº¥n náº¿u pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng lÃ  pháº§n tiáº¿p ná»‘i hoáº·c lÃ m rÃµ ná»™i dung trong há»™i thoáº¡i trÆ°á»›c Ä‘Ã³.", náº¿u pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng khÃ´ng tráº£ lá»i hoáº·c khÃ´ng liÃªn quan cho cuá»™c há»™i thoáº¡i gáº§n Ä‘Ã¢y thÃ¬ hÃ£y tráº£ vá» y nguyÃªn pháº£n há»“i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng.

        """
        # assume async predict exists
        enriched = await self.llm.ainvoke(prompt)
        print("==== RAW RESPONSE ====")
        print(enriched.content)
        print("======================")
        # fallback: if empty use original
        enriched_txt = (enriched.content or "").strip().splitlines()[0] if enriched else user_message
        return enriched_txt   

    # ---------------------------
    # LLM relevance check: ensure enriched_query actually matches the training QA
    # ---------------------------
    async def llm_relevance_check(self, enriched_query: str, matched_question: str, answer: str) -> bool:
        prompt = f"""
        Báº¡n lÃ  chuyÃªn gia Ä‘Ã¡nh giÃ¡ giá»¯a cÃ¢u há»i tÃ¬m kiáº¿m, cÃ¢u há»i trong cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ  cÃ¢u tráº£ lá»i cho 1 há»‡ thá»‘ng chat RAG tuyá»ƒn sinh, hÃ£y suy luáº­n. 

        CÃ¢u há»i tÃ¬m kiáº¿m (Ä‘Ã£ chuáº©n hÃ³a): "{enriched_query}"
        CÃ¢u há»i DB: "{matched_question}"
        CÃ¢u tráº£ lá»i chÃ­nh thá»©c: "{answer}"

        HÃ£y tráº£ lá»i duy nháº¥t chá»‰ má»™t tá»«: "true" náº¿u cÃ¢u há»i DB phÃ¹ há»£p vÃ  tráº£ lá»i Ä‘Ã³ há»£p lÃ½ cho truy váº¥n tÃ¬m kiáº¿m; "false" náº¿u chá»‰ trÃ¹ng tá»« khÃ³a hoáº·c khÃ´ng phÃ¹ há»£p.
        Hoáº·c cÃ³ thá»ƒ tráº£ vá» "true" náº¿u cÃ¢u há»i tÃ¬m kiáº¿m chá»‰ lÃ  lá»i chÃ o.
        """
        res = await self.llm.ainvoke(prompt)
        if not res.content:
            return False
        r = res.content.strip().lower()
        return ("Ä‘Ãºng" in r) or ("true" in r) or (r.startswith("Ä‘Ãºng")) or (r.startswith("true"))

    async def llm_document_recommendation_check(self, enriched_query: str, context: str) -> bool:
        prompt = f"""
        Báº¡n lÃ  há»‡ thá»‘ng kiá»ƒm tra 2 táº§ng:
        - Táº§ng 1 lÃ  há»‡ thá»‘ng kiá»ƒm tra má»©c Ä‘á»™ liÃªn quan giá»¯a cÃ¢u há»i ngÆ°á»i dÃ¹ng vÃ  ná»™i dung trong Document Base (RAG) cho chatbot RAG tÆ° váº¥n tuyá»ƒn sinh.
        - Táº§ng 2 lÃ  há»‡ thá»‘ng kiá»ƒm tra má»©c Ä‘á»™ liÃªn quan giá»¯a cÃ¢u há»i ngÆ°á»i dÃ¹ng cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung tÆ° váº¥n ngÃ nh há»c hay tÆ° váº¥n cho cÃ¡ nhÃ¢n dá»±a theo há»“ sÆ¡ cá»§a há»c sinh hoáº·c nhá»¯ng cÃ¢u liÃªn quan Ä‘áº¿n RIASEC, há»c báº¡, GPA, sá»Ÿ thÃ­ch, nguyá»‡n vá»ng cÃ¡ nhÃ¢n; hoáº·c yÃªu cáº§u so sÃ¡nh ngÃ nh theo profile; hoáº·c yÃªu cáº§u gá»£i Ã½ ngÃ nh phÃ¹ há»£p cho chatbot RAG tÆ° váº¥n tuyá»ƒn sinh.
        YÃªu cáº§u kiá»ƒm tra cÃ¢u há»i ngÆ°á»i dÃ¹ng cÃ³ phÃ¹ há»£p vá»›i táº§ng 1 hoáº·c táº§ng 2:
        - Náº¿u phÃ¹ há»£p vá»›i táº§ng 1 thÃ¬ tráº£ vá» duy nháº¥t 1 tá»« "document"
        - Náº¿u phÃ¹ há»£p vá»›i táº§ng 2 thÃ¬ tráº£ vá» duy nháº¥t 1 tá»« "recommendation"
        - Náº¿u táº§ng 1 phÃ¹ há»£p thÃ¬ khÃ´ng cáº§n check Ä‘áº¿n táº§ng 2
        - Náº¿u khÃ´ng phÃ¹ há»£p vá»›i táº§ng 1 vÃ  táº§ng 2 thÃ¬ tráº£ vá» duy nháº¥t 1 tá»« "Nope"
        - Check táº§ng 1(document) Ä‘áº§u tiÃªn:
        - Chá»‰ tráº£ vá» "document" náº¿u Ná»˜I DUNG cá»§a document base THá»°C Sá»° cÃ³ thÃ´ng tin tráº£ lá»i cÃ¢u há»i hoáº·c cÃ¢u há»i ngÆ°á»i dÃ¹ng chá»‰ lÃ  nhá»¯ng lá»i chÃ o.
        - Check qua táº§ng 2 náº¿u:
            â€¢ chá»‰ trÃ¹ng tá»« khÃ³a nhÆ°ng khÃ´ng cÃ¹ng Ã½ nghÄ©a
            â€¢ document khÃ´ng chá»©a dá»¯ liá»‡u cáº§n thiáº¿t Ä‘á»ƒ tráº£ lá»i
            â€¢ truy váº¥n lÃ  yÃªu cáº§u tÆ° váº¥n cÃ¡ nhÃ¢n (Recommendation), khÃ´ng pháº£i tÃ¬m kiáº¿n thá»©c
            â€¢ query chung chung nhÆ°: "tÃ´i há»£p ngÃ nh nÃ o", "hÃ£y tÆ° váº¥n", "mÃ´ táº£ vá» tÃ´i", "nÃªn há»c gÃ¬"
            â€¢ context khÃ´ng cung cáº¥p thÃ´ng tin trá»±c tiáº¿p liÃªn quan
        - Check táº§ng 2(recommendation):
        - Chá»‰ tráº£ vá» "recommendation" náº¿u cÃ¢u há»i ngÆ°á»i dÃ¹ng liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung tÆ° váº¥n ngÃ nh há»c hay tÆ° váº¥n cho cÃ¡ nhÃ¢n dá»±a theo há»“ sÆ¡ cá»§a há»c sinh hoáº·c nhá»¯ng cÃ¢u liÃªn quan Ä‘áº¿n RIASEC, há»c báº¡, GPA, sá»Ÿ thÃ­ch, nguyá»‡n vá»ng cÃ¡ nhÃ¢n; hoáº·c yÃªu cáº§u so sÃ¡nh ngÃ nh theo profile; hoáº·c yÃªu cáº§u gá»£i Ã½ ngÃ nh phÃ¹ há»£p
        - Chá»‰ tráº£ vá» "Nope" khi cáº£ táº§ng 1 vÃ  táº§ng 2 Ä‘á»u khÃ´ng liÃªn quan Ä‘áº¿n cÃ¢u há»i ngÆ°á»i dÃ¹ng.
        
        CÃ¢u há»i ngÆ°á»i dÃ¹ng: "{enriched_query}"

        Ná»™i dung Document Base (context):
        \"\"\"
        {context}
        \"\"\"

        
        """

        res = await self.llm.ainvoke(prompt)
        r = res.content.strip().lower()
        if r not in ["document", "recommendation", "nope"]:
            r = "nope"
        return r

    async def llm_suitable_for_recommedation_check(self, enriched_query: str, context: str) -> bool:
        prompt = f"""
        Báº¡n lÃ  há»‡ thá»‘ng kiá»ƒm tra má»©c Ä‘á»™ liÃªn quan giá»¯a cÃ¢u há»i ngÆ°á»i dÃ¹ng cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung tÆ° váº¥n ngÃ nh há»c hay tÆ° váº¥n cho cÃ¡ nhÃ¢n dá»±a theo há»“ sÆ¡ cá»§a há»c sinh hoáº·c nhá»¯ng cÃ¢u liÃªn quan Ä‘áº¿n RIASEC, há»c báº¡, GPA, sá»Ÿ thÃ­ch, nguyá»‡n vá»ng cÃ¡ nhÃ¢n; hoáº·c yÃªu cáº§u so sÃ¡nh ngÃ nh theo profile; hoáº·c yÃªu cáº§u gá»£i Ã½ ngÃ nh phÃ¹ há»£p cho chatbot RAG tÆ° váº¥n tuyá»ƒn sinh.

        YÃªu cáº§u:
        - Chá»‰ tráº£ vá» "true" náº¿u cÃ¢u há»i cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung Ä‘Ã³.
        - Tráº£ vá» "false" náº¿u cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung Ä‘Ã³.

        CÃ¢u há»i ngÆ°á»i dÃ¹ng: "{enriched_query}"

        
        HÃ£y TRáº¢ Lá»œI DUY NHáº¤T:
        - "true" â†’ náº¿u cÃ¢u há»i cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung Ä‘Ã³ 
        - "false" â†’ náº¿u cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung Ä‘Ã³
        """

        res = await self.llm.ainvoke(prompt)
        if not res.content:
            return False
        r = res.content.strip().lower()
        return ("Ä‘Ãºng" in r) or ("true" in r) or (r.startswith("Ä‘Ãºng")) or (r.startswith("true"))

    async def response_from_riasec_result(self, riasec_result: schemas.RiasecResultCreate):
        prompt = f"""
        Báº¡n lÃ  chuyÃªn gia hÆ°á»›ng nghiá»‡p Holland (RIASEC).

        DÆ°á»›i Ä‘Ã¢y lÃ  Ä‘iá»ƒm RIASEC cá»§a ngÆ°á»i dÃ¹ng:
        - Realistic (R): {riasec_result.score_realistic}
        - Investigative (I): {riasec_result.score_investigative}
        - Artistic (A): {riasec_result.score_artistic}
        - Social (S): {riasec_result.score_social}
        - Enterprising (E): {riasec_result.score_enterprising}
        - Conventional (C): {riasec_result.score_conventional}

        YÃªu cáº§u:
        1. Tá»± xÃ¡c Ä‘á»‹nh mÃ£ RIASEC chÃ­nh cá»§a ngÆ°á»i dÃ¹ng báº±ng cÃ¡ch chá»n 3 nhÃ³m cÃ³ Ä‘iá»ƒm cao nháº¥t (vÃ­ dá»¥: â€œISAâ€, â€œREIâ€, â€œSECâ€â€¦).
        2. Giáº£i thÃ­ch Ã½ nghÄ©a mÃ£ RIASEC Ä‘Ã³ theo phong cÃ¡ch hÆ°á»›ng nghiá»‡p.
        3. TÃ³m táº¯t Ä‘áº·c Ä‘iá»ƒm tÃ­nh cÃ¡ch chÃ­nh (3â€“5 cÃ¢u).
        4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, sá»­ dá»¥ng Markdown (tiÃªu Ä‘á», gáº¡ch Ä‘áº§u dÃ²ng, xuá»‘ng dÃ²ng rÃµ rÃ ng).

        Tráº£ vá»:
        - Má»™t Ä‘oáº¡n vÄƒn hoÃ n chá»‰nh, bao gá»“m cáº£ mÃ£ RIASEC mÃ  báº¡n suy luáº­n.
            """

        try:
            res = await self.llm.ainvoke(prompt)
            return res.content.strip()

        except Exception as e:
            print("LLM error:", e)
            return "Xin lá»—i, há»‡ thá»‘ng táº¡m thá»i chÆ°a thá»ƒ phÃ¢n tÃ­ch káº¿t quáº£ RIASEC. Báº¡n vui lÃ²ng thá»­ láº¡i sau."

    async def load_session_history_to_memory(self, session_id: int, db: Session):
        memory = memory_service.get_memory(session_id)

        # Láº¥y lá»‹ch sá»­ chat theo thá»© tá»± thá»i gian
        interactions = (
            db.query(ChatInteraction)
            .filter(ChatInteraction.session_id == session_id)
            .order_by(ChatInteraction.timestamp.asc())
            .all()
        )

        last_user_msg = None
        for inter in interactions:
            if not inter.is_from_bot:
                # user message
                last_user_msg = inter.message_text
            else:
                # bot message -> káº¿t há»£p vá»›i user message trÆ°á»›c Ä‘Ã³ (náº¿u cÃ³)
                memory.save_context(
                    {"input": last_user_msg or ""},
                    {"output": inter.message_text}
                )
                last_user_msg = None

        # Náº¿u cuá»‘i cÃ¹ng lÃ  tin nháº¯n user chÆ°a Ä‘Æ°á»£c pháº£n há»“i
        if last_user_msg:
            memory.save_context({"input": last_user_msg}, {"output": ""})

    def update_faq_statistics(self, db: Session, question_text: str, answer_text: str, intent_id: int = 1):
        """
        TÄƒng usage_count cho má»™t Q&A Ä‘Ã£ dÃ¹ng (Tier 1).
        - Táº¡o má»›i náº¿u chÆ°a cÃ³.
        - Cáº­p nháº­t usage_count vÃ  last_used_at náº¿u Ä‘Ã£ tá»“n táº¡i.
        """
        try:
            faq_stat = db.query(FaqStatistics).filter(FaqStatistics.intent_id == intent_id).first()

            if faq_stat:
                # Cáº­p nháº­t náº¿u Ä‘Ã£ tá»“n táº¡i
                faq_stat.usage_count =  (faq_stat.usage_count or 0) + 1
                faq_stat.last_used_at = datetime.now()
            else:
                # Táº¡o má»›i náº¿u chÆ°a tá»“n táº¡i
                new_stat = FaqStatistics(
                    usage_count=1,
                    success_rate=None,
                    question_text=question_text,  # Placeholder
                    answer_text=answer_text,      # Placeholder
                    rating=None,
                    last_used_at=datetime.now(),
                    intent_id=intent_id
                )
                db.add(new_stat)

            db.commit()
            

        except Exception as e:
            db.rollback()
            print(f"Error updating FaqStatistics: {e}")
            

    async def stream_response_from_context(self, query: str, context: str, session_id: int, user_id: int, intent_id: int, message: str):
        db = SessionLocal()
        
        try:
            if user_id:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=None,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            else:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=user_id,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            memory = memory_service.get_memory(session_id)
            mem_vars = memory.load_memory_variables({})
            chat_history = mem_vars.get("chat_history", "")
            

            prompt = f"""Báº¡n lÃ  má»™t tÆ° váº¥n viÃªn tuyá»ƒn sinh chuyÃªn nghiá»‡p cá»§a trÆ°á»ng Ä‘áº¡i há»c FPT
            ÄÃ¢y lÃ  Ä‘oáº¡n há»™i thoáº¡i trÆ°á»›c: 
            {chat_history}
            === THÃ”NG TIN THAM KHáº¢O ===
            {context}
            === CÃ‚U Há»ŽI ===
            {query}
            === HÆ¯á»šNG DáºªN ===
            - Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
            - Dá»±a vÃ o thÃ´ng tin tham kháº£o trÃªn Ä‘Æ°á»£c cung cáº¥p
            - Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng Markdown: dÃ¹ng tiÃªu Ä‘á» ##, gáº¡ch Ä‘áº§u dÃ²ng -, xuá»‘ng dÃ²ng rÃµ rÃ ng.
            - HÃ£y táº¡o ra cÃ¢u tráº£ lá»i khÃ´ng quÃ¡ dÃ i, gÃ³i gá»n Ã½ chÃ­nh, chá»‰ khi cÃ¢u há»i yÃªu cáº§u "chi tiáº¿t" thÃ¬ má»›i táº¡o cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§
            - Báº¡n lÃ  tÆ° váº¥n tuyá»ƒn sinh cá»§a trÆ°á»ng Ä‘áº¡i há»c FPT, náº¿u thÃ´ng tin cÃ¢u há»i yÃªu cÃ¢u tÃªn 1 trÆ°á»ng khÃ¡c thÃ¬ hÃ£y nÃ³i rÃµ ra lÃ  khÃ´ng tÃ¬m tháº¥y thÃ´ng tin
            - Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, hÃ£y nÃ³i rÃµ vÃ  gá»£i Ã½ liÃªn há»‡ trá»±c tiáº¿p nhÃ¢n viÃªn tÆ° váº¥n
            - KhÃ´ng cáº§n pháº£i chÃ o há»i má»—i láº§n tráº£ lá»i, vÃ o tháº³ng váº¥n Ä‘á» chÃ­nh
            - Náº¿u cÃ¢u há»i chá»‰ lÃ  chÃ o há»i, hoáº·c cÃ¡c cÃ¢u xÃ£ giao, hÃ£y tráº£ lá»i báº±ng lá»i chÃ o thÃ¢n thiá»‡n, giá»›i thiá»‡u vá» báº£n thÃ¢n chatbot, KHÃ”NG kÃ©o thÃªm thÃ´ng tin chi tiáº¿t trong context.
            - Khi cÃ³ thá»ƒ, hÃ£y **giáº£i thÃ­ch thÃªm bá»‘i cáº£nh hoáº·c gá»£i Ã½ bÆ°á»›c tiáº¿p theo**, vÃ­ dá»¥:  
                â€œBáº¡n muá»‘n mÃ¬nh gá»­i danh sÃ¡ch ngÃ nh Ä‘Ã o táº¡o kÃ¨m chuyÃªn ngÃ nh chi tiáº¿t khÃ´ng?â€  
                hoáº·c  
                â€œNáº¿u báº¡n quan tÃ¢m há»c bá»•ng, mÃ¬nh cÃ³ thá»ƒ nÃ³i rÃµ cÃ¡c loáº¡i há»c bá»•ng hiá»‡n cÃ³ nhÃ©!â€
            """
            full_response = ""
            async for chunk in self.llm.astream(prompt):
                text = chunk.content or ""
                full_response += text
                yield text
                await asyncio.sleep(0)  # NhÆ°á»ng event loop
            print(full_response)
            memory.save_context({"input": query}, {"output": full_response})  
            
            # === ðŸ”¥ LÆ°u bot response vÃ o DB ===
            bot_msg = ChatInteraction(
                message_text=full_response,
                timestamp=datetime.now(),
                rating=None,
                is_from_bot=True,
                sender_id=None,
                session_id=session_id
            )
            db.add(bot_msg)



            # ðŸ§© 5. Commit 1 láº§n duy nháº¥t
            db.commit()
            self.update_faq_statistics(db, question_text = query, answer_text = full_response, intent_id = intent_id)
            print(f"ðŸ’¾ Saved both user+bot messages for session {session_id}")
        except SQLAlchemyError as e:
            db.rollback()
            print(f" Database error during chat transaction: {e}")
        finally:
            db.close()

    async def stream_response_from_qa(self, query: str, context: str, session_id: int = 1, user_id: int = 1, intent_id: int = 1, message: str = ""):
        db = SessionLocal()
        try:
            if user_id:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=None,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            else:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=user_id,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            memory = memory_service.get_memory(session_id)
            mem_vars = memory.load_memory_variables({})
            chat_history = mem_vars.get("chat_history", "")

            prompt = f"""
            Báº¡n lÃ  chatbot tÆ° váº¥n tuyá»ƒn sinh cá»§a trÆ°á»ng Ä‘áº¡i há»c FPT.
            ÄÃ¢y lÃ  Ä‘oáº¡n há»™i thoáº¡i trÆ°á»›c: 
            {chat_history}
            === CÃ‚U TRáº¢ Lá»œI CHÃNH THá»¨C ===
            {context}

            === CÃ‚U Há»ŽI NGÆ¯á»œI DÃ™NG ===
            {query}

            === HÆ¯á»šNG DáºªN TRáº¢ Lá»œI ===
            - HÃ£y Ä‘á»c ká»¹ pháº§n NGá»® Cáº¢NH LIÃŠN QUAN, nhÆ°ng **chá»‰ sá»­ dá»¥ng nÃ³ náº¿u tháº­t sá»± cÃ³ ná»™i dung trÃ¹ng khá»›p hoáº·c phÃ¹ há»£p vá»›i cÃ¢u há»i ngÆ°á»i dÃ¹ng.**
            - Náº¿u pháº§n CÃ‚U TRáº¢ Lá»œI CHÃNH THá»¨C khÃ´ng liÃªn quan rÃµ rÃ ng Ä‘áº¿n cÃ¢u há»i, **Ä‘á»«ng cá»‘ tráº£ lá»i theo context** mÃ  hÃ£y nÃ³i:
            â€œHiá»‡n chÆ°a cÃ³ thÃ´ng tin chÃ­nh xÃ¡c cho cÃ¢u há»i nÃ y. Báº¡n cÃ³ thá»ƒ nÃ³i rÃµ chi tiáº¿t hÆ¡n Ä‘Æ°á»£c khÃ´ng?â€ 
            - Náº¿u pháº§n tráº£ lá»i chÃ­nh thá»©c khÃ´ng phÃ¹ há»£p vá»›i cÃ¢u há»i, hÃ£y nÃ³i â€œHiá»‡n chÆ°a cÃ³ thÃ´ng tin cho cÃ¢u há»i nÃ y. Vui lÃ²ng liÃªn há»‡ chuyÃªn viÃªn tÆ° váº¥n.â€
            - Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng Markdown: dÃ¹ng tiÃªu Ä‘á» ##, gáº¡ch Ä‘áº§u dÃ²ng -, xuá»‘ng dÃ²ng rÃµ rÃ ng.
            - HÃ£y táº¡o ra cÃ¢u tráº£ lá»i khÃ´ng quÃ¡ dÃ i, gÃ³i gá»n Ã½ chÃ­nh, chá»‰ khi cÃ¢u há»i yÃªu cáº§u "chi tiáº¿t" thÃ¬ má»›i táº¡o cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§
            - Báº¡n lÃ  chatbot tÆ° váº¥n tuyá»ƒn sinh cá»§a trÆ°á»ng Ä‘áº¡i há»c FPT, nhá»› kiá»ƒm tra kÄ© rÃµ rÃ ng cÃ¢u há»i, náº¿u thÃ´ng tin cÃ¢u há»i yÃªu cÃ¢u tÃªn 1 trÆ°á»ng khÃ¡c thÃ¬ hÃ£y nÃ³i rÃµ ra lÃ  khÃ´ng tÃ¬m tháº¥y thÃ´ng tin
            - Náº¿u cÃ¢u há»i chá»‰ lÃ  chÃ o há»i, há»i thá»i tiáº¿t, hoáº·c cÃ¡c cÃ¢u xÃ£ giao, hÃ£y tráº£ lá»i báº±ng lá»i chÃ o thÃ¢n thiá»‡n, giá»›i thiá»‡u vá» báº£n thÃ¢n chatbot, KHÃ”NG kÃ©o thÃªm thÃ´ng tin chi tiáº¿t trong context.
            - KhÃ´ng cáº§n pháº£i chÃ o há»i má»—i láº§n tráº£ lá»i, vÃ o tháº³ng váº¥n Ä‘á» chÃ­nh
            - Náº¿u cÃ¢u há»i quÃ¡ mÆ¡ há»“, hÃ£y há»i láº¡i Ä‘á»ƒ rÃµ hÆ¡n vÃ  chi tiáº¿t hÆ¡n vá» cÃ¢u há»i
            - CÃ³ thá»ƒ **diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i hoáº·c thÃ´ng tin** má»™t cÃ¡ch nháº¹ nhÃ ng, tá»± nhiÃªn Ä‘á»ƒ ngÆ°á»i dÃ¹ng dá»… hiá»ƒu hÆ¡n, **nhÆ°ng tuyá»‡t Ä‘á»‘i khÃ´ng thay Ä‘á»•i Ã½ nghÄ©a hay thÃªm dá»¯ kiá»‡n má»›i.**
            - Khi cÃ³ thá»ƒ, hÃ£y **giáº£i thÃ­ch thÃªm bá»‘i cáº£nh hoáº·c gá»£i Ã½ bÆ°á»›c tiáº¿p theo**, vÃ­ dá»¥:  
                â€œBáº¡n muá»‘n mÃ¬nh gá»­i danh sÃ¡ch ngÃ nh Ä‘Ã o táº¡o kÃ¨m chuyÃªn ngÃ nh chi tiáº¿t khÃ´ng?â€  
                hoáº·c  
                â€œNáº¿u báº¡n quan tÃ¢m há»c bá»•ng, mÃ¬nh cÃ³ thá»ƒ nÃ³i rÃµ cÃ¡c loáº¡i há»c bá»•ng hiá»‡n cÃ³ nhÃ©!â€
            """
            full_response = ""
            async for chunk in self.llm.astream(prompt):
                text = chunk.content or ""
                full_response += text
                yield text
                await asyncio.sleep(0)  # NhÆ°á»ng event loop

            memory.save_context({"input": query}, {"output": full_response})  
            print("Saved to memory. Current messages:", len(memory.chat_memory.messages))

            # === LÆ°u bot response vÃ o DB ===
            bot_msg = ChatInteraction(
                message_text=full_response,
                timestamp=datetime.now(),
                rating=None,
                is_from_bot=True,
                sender_id=None,
                session_id=session_id
            )
            db.add(bot_msg)

            # ðŸ§© 5. Commit 1 láº§n duy nháº¥t
            db.commit()
            self.update_faq_statistics(db, question_text = query, answer_text = full_response, intent_id = intent_id)
            print(f"ðŸ’¾ Saved both user+bot messages for session {session_id}")
        except SQLAlchemyError as e:
            db.rollback()
            print(f" Database error during chat transaction: {e}")
        finally:
            db.close() 
    
    async def stream_response_from_recommendation(
        self,
        user_id: int,
        session_id: int,
        query: str,
        message: str
    ):
        db = SessionLocal()
        try:
            if user_id:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=None,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            else:
                # ðŸ§© 1. LÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng
                user_msg = ChatInteraction(
                    message_text=message,
                    timestamp=datetime.now(),
                    rating=None,
                    is_from_bot=False,
                    sender_id=user_id,
                    session_id=session_id
                )
                db.add(user_msg)
                db.flush()  # flush Ä‘á»ƒ láº¥y ID náº¿u cáº§n liÃªn káº¿t sau
            memory = memory_service.get_memory(session_id)
            mem_vars = memory.load_memory_variables({})
            chat_history = mem_vars.get("chat_history", "")

            user_profile = self._get_user_personality_and_academics(user_id, db)
            majors = self._get_all_majors_and_specialization_from_db(db, limit=200)

            personality = user_profile.get("personality_summary") or ""
            academic_summary = user_profile.get("academic_summary") or ""
            gpa = user_profile.get("gpa", "")

            maj_texts = []
            for m in majors:
                line = f"- [{m['major_id']}]: {m['major_name']}"
                
                if m["specializations"]:
                    for s in m["specializations"]:
                        line += f"\n    â€¢ {s['specialization_name']}"
                
                maj_texts.append(line)

            prompt = f"""
        Báº¡n lÃ  chatbot tÆ° váº¥n tuyá»ƒn sinh cá»§a trÆ°á»ng Ä‘áº¡i há»c FPT. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tÆ° váº¥n chá»n ngÃ nh:
        **CHá»ˆ tÆ° váº¥n chá»n ngÃ nh khi cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng tháº­t sá»± liÃªn quan.**
        
        ÄÃ¢y lÃ  Ä‘oáº¡n há»™i thoáº¡i trÆ°á»›c: 
            {chat_history}
        ===========================
        ### THÃ”NG TIN Há»’ SÆ  NGÆ¯á»œI DÃ™NG
        Personality summary(RIASEC Result):
        {personality}

        Academic summary(há»c báº¡):
        {academic_summary}

        

        ===========================
        ### DANH SÃCH CÃC NGÃ€NH
        {chr(10).join(maj_texts)}

        ===========================
        ### CÃ‚U Há»ŽI NGÆ¯á»œI DÃ™NG
        "{query}"

        ===========================
        ### HÆ¯á»šNG DáºªN Xá»¬ LÃ

        1. **Äáº§u tiÃªn, hÃ£y kiá»ƒm tra xem cÃ¢u há»i cÃ³ tháº­t sá»± liÃªn quan Ä‘áº¿n viá»‡c tÆ° váº¥n chá»n ngÃ nh hay khÃ´ng, hoáº·c cÃ¢u há»i cÃ³ liÃªn quan Ä‘áº¿n thÃ´ng tin há»“ sÆ¡ ngÆ°á»i dÃ¹ng hay khÃ´ng.**
        - Náº¿u KHÃ”NG liÃªn quan â†’ báº¡n hÃ£y tá»± táº¡o cÃ¢u pháº£n há»“i phÃ¹ há»£p vá»›i CÃ‚U Há»ŽI NGÆ¯á»œI DÃ™NG
        2. Náº¿u cÃ¢u há»i cÃ³ liÃªn quan Ä‘áº¿n thÃ´ng tin há»“ sÆ¡ ngÆ°á»i dÃ¹ng á»Ÿ trÃªn bao gá»“m RIASEC Result vÃ  há»c báº¡ mÃ  há»“ sÆ¡ ngÆ°á»i dÃ¹ng trá»‘ng thÃ¬ hÃ£y yÃªu cáº§u ngÆ°á»i dÃ¹ng nháº­p nhá»¯ng thÃ´ng tin nÃ y nhÆ° RIASEC Result hoáº·c há»c báº¡, 1 trong 2 lÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c tÆ° váº¥n dá»±a vÃ o thÃ´ng tin há»“ sÆ¡ ngÆ°á»i dÃ¹ng. Äá» xuáº¥t theo tÃ­nh cÃ¡ch cÃ³ thá»ƒ dá»±a vÃ o káº¿t quáº£ RIASEC Result cá»§a THÃ”NG TIN Há»’ SÆ  NGÆ¯á»œI DÃ™NG
        3. Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng Markdown: dÃ¹ng tiÃªu Ä‘á» ##, gáº¡ch Ä‘áº§u dÃ²ng -, xuá»‘ng dÃ²ng rÃµ rÃ ng.
        4. Náº¿u cÃ¢u há»i khÃ´ng liÃªn quan thÃ¬ hÃ£y tá»« chá»‘i yÃªu cáº§u vÃ  Ä‘á» nghá»‹ nháº¯n trá»±c tiáº¿p bÃªn tuyá»ƒn sinh
        5. KhÃ´ng cáº§n pháº£i chÃ o há»i má»—i láº§n tráº£ lá»i, vÃ o tháº³ng váº¥n Ä‘á» chÃ­nh
        """
            full_response = ""
            async for chunk in self.llm.astream(prompt):
                text = chunk.content or ""
                full_response += text
                yield text
                await asyncio.sleep(0)  # NhÆ°á»ng event loop

            memory.save_context({"input": query}, {"output": full_response})  
            print("Saved to memory. Current messages:", len(memory.chat_memory.messages))

            # === LÆ°u bot response vÃ o DB ===
            bot_msg = ChatInteraction(
                message_text=full_response,
                timestamp=datetime.now(),
                rating=None,
                is_from_bot=True,
                sender_id=None,
                session_id=session_id
            )
            db.add(bot_msg)

            # ðŸ§© 5. Commit 1 láº§n duy nháº¥t
            db.commit()
            print(f"ðŸ’¾ Saved both user+bot messages for session {session_id}")
        except SQLAlchemyError as e:
            db.rollback()
            print(f" Database error during chat transaction: {e}")
        finally:
            db.close()

    def create_training_qa(self, db: Session, intent_id: int, question: str, answer: str, created_by: int):
        qa = TrainingQuestionAnswer(
            question=question,
            answer=answer,
            intent_id=intent_id,
            created_by=created_by,
            status="draft"
        )
        db.add(qa)
        db.commit()
        db.refresh(qa)

        return qa

    def approve_training_qa(self, db: Session, qa_id: int, reviewer_id: int):
        qa = db.query(TrainingQuestionAnswer).filter_by(question_id=qa_id).first()
        if not qa:
            raise Exception("QA not found")

        if qa.status != "draft":
            raise Exception("Only draft QA can be approved")

        # embed question (answer khÃ´ng embed)
        embedding = self.embeddings.embed_query(qa.question)
        point_id = str(uuid.uuid4())

        # push to Qdrant
        self.qdrant_client.upsert(
            collection_name="training_qa",
            points=[
                PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload={
                        "question_id": qa.question_id,
                        "intent_id": qa.intent_id,
                        "question_text": qa.question,
                        "answer_text": qa.answer,
                        "type": "training_qa"
                    }
                )
            ]
        )

        # update DB
        qa.status = "approved"
        qa.approved_by = reviewer_id
        qa.approved_at = datetime.now().date()  # Convert datetime to date
        db.commit()

        return {
            "postgre_question_id": qa.question_id,
            "qdrant_question_id": point_id
        }

    def delete_training_qa(self, db: Session, qa_id: int):
        
        qa = db.query(TrainingQuestionAnswer).filter_by(question_id=qa_id).first()
        if not qa:
            raise Exception("Training QA not found")

        # XÃ³a vector trong Qdrant
        self.qdrant_client.delete(
            collection_name="training_qa",
            points_selector=models.FilterSelector(
                filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="question_id",
                            match=models.MatchValue(qa_id)
                        )
                    ]
                )
            )
        )

        # XÃ³a trong DB
        db.delete(qa)
        db.commit()

        return {"deleted_question_id": qa_id}

    def create_document(self, db: Session, title: str, file_path: str, intend_id: int, created_by: int):
        new_doc = KnowledgeBaseDocument(
            title=title,
            file_path=file_path,
            intend_id=intend_id,
            status="draft",
            created_by=created_by,
        )
        db.add(new_doc)
        db.commit()
        db.refresh(new_doc)

        return new_doc

    def approve_document(self, db: Session, document_id: int, reviewer_id: int, intent_id: int, metadata: dict = None):

        doc = db.query(KnowledgeBaseDocument).filter_by(document_id=document_id).first()
        if not doc:
            raise Exception("Document not found")

        if doc.status != "draft":
            raise Exception("Only draft documents can be approved")

        abs_path = os.path.abspath(doc.file_path)
        print("OPEN FILE:", abs_path)

        with open(abs_path, "rb") as f:
            file_bytes = f.read()

        # 3. Detect MIME type tá»« extension (DocumentProcessor cáº§n)
        mime_map = {
            ".pdf":  "application/pdf",
            ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ".doc":  "application/msword",
            ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            ".xls":  "application/vnd.ms-excel",
            ".pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            ".txt":  "text/plain",
        }
        ext = os.path.splitext(doc.file_path)[1].lower()
        mime_type = mime_map.get(ext, "text/plain")
        content = DocumentProcessor.extract_text(
        file_content=file_bytes,
        filename=os.path.basename(doc.file_path),
        mime_type=mime_type
        )
        # --- Split text ---
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_text(content)

        qdrant_ids = []

        # --- Save chunks to DB & Qdrant ---
        for i, chunk in enumerate(chunks):

            # # Save DocumentChunk in DB
            # db_chunk = DocumentChunk(
            #     chunk_text=chunk,
            #     document_id=document_id,
            #     created_by=reviewer_id
            # )
            # db.add(db_chunk)
            # db.flush()   # get chunk_id

            # Embed
            embedding = self.embeddings.embed_query(chunk)
            point_id = str(uuid.uuid4())

            # Push to Qdrant
            self.qdrant_client.upsert(
                collection_name="knowledge_base_documents",
                points=[
                    PointStruct(
                        id=point_id,
                        vector=embedding,
                        payload={
                            "document_id": document_id,
                            "chunk_index": i,
                            "chunk_text": chunk,
                            "intent_id": intent_id,
                            "metadata": metadata or {},
                            "type": "document"
                        }
                    )
                ]
            )

            qdrant_ids.append(point_id)

        # update document status
        doc.status = "approved"
        doc.reviewed_by = reviewer_id
        doc.reviewed_at = datetime.now().date()  # Convert datetime to date
        db.commit()

        return {
            "document_id": document_id,
            "status": doc.status
        }

    def delete_document(self, db: Session, document_id: int):
        doc = db.query(KnowledgeBaseDocument).filter_by(document_id=document_id).first()
        if not doc:
            raise Exception("Document not found")

        # XÃ³a sáº¡ch vector trong Qdrant
        self.qdrant_client.delete(
            collection_name="knowledge_base_documents",
            points_selector=models.FilterSelector(
                filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="document_id",
                            match=models.MatchValue(document_id)
                        )
                    ]
                )
            )
        )

        # XÃ³a chunks trong DB
        dl = db.query(DocumentChunk).filter_by(document_id=document_id)
        if dl:
            dl.delete()
        # XÃ³a document trong DB
        db.delete(doc)
        db.commit()

        return {"deleted_document_id": document_id}
    



    # def add_document(self, document_id: int, content: str, intend_id: int, metadata: dict = None):
    #     text_splitter = RecursiveCharacterTextSplitter(
    #         chunk_size=1000,      # Size optimal cho Vietnamese
    #         chunk_overlap=200     # Overlap to preserve context
    #     )
    #     chunks = text_splitter.split_text(content)
        
    #     chunk_ids = []
    #     for i, chunk in enumerate(chunks):
    #         # Embed chunk
    #         embedding = self.embeddings.embed_query(chunk)
    #         point_id = str(uuid.uuid4())
            
    #         # Upsert to Qdrant
    #         self.qdrant_client.upsert(
    #             collection_name="knowledge_base_documents",
    #             points=[
    #                 PointStruct(
    #                     id=point_id,
    #                     vector=embedding,
    #                     payload={
    #                         "document_id": document_id,
    #                         "chunk_index": i,
    #                         "chunk_text": chunk,
    #                         "intend_id": intend_id,
    #                         "metadata": metadata or {},
    #                         "type": "document"
    #                     }
    #                 )
    #             ]
    #         )
    #         chunk_ids.append(point_id)
        
    #     return chunk_ids
    
    def add_training_qa(self, db: Session, intent_id: int, question_text: str, answer_text: str):
        """
        Add training Q&A pair vÃ o Qdrant
        
        Chá»‰ embed question, khÃ´ng embed answer:
        - Answer stored á»Ÿ DB, retrieve khi match found
        - Question dÃ¹ng Ä‘á»ƒ search/match
        - Tiáº¿t kiá»‡m storage, tÄƒng search speed
        
        Args:
            question_id: Primary key cá»§a training Q&A
            intent_id: Intent nÃ y thuá»™c intent nÃ o
            question_text: Question Ä‘á»ƒ embed
            answer_text: Answer (lÆ°u á»Ÿ DB, khÃ´ng embed)
        
        Returns:
            embedding_id: Qdrant point ID
        """
        new_qa = TrainingQuestionAnswer(
            question=question_text,
            answer=answer_text,
            intent_id=1,
            created_by=1,
            status='draft'  # New Q&A starts as draft, needs review before training
        )
        db.add(new_qa)
        db.commit()
        db.refresh(new_qa)
        # Embed question text
        embedding = self.embeddings.embed_query(question_text)
        point_id = str(uuid.uuid4())
        
        # Upsert vÃ o training_qa collection
        # Metadata:
        # - question_id: Link vá» DB
        # - intent_id: Äá»ƒ track intent stats
        # - question_text: LÆ°u original text (optional, space saving)
        # - answer_text: LÆ°u answer (retrieve khi match)
        self.qdrant_client.upsert(
            collection_name=self.training_qa_collection,
            points=[
                PointStruct(
                    id=point_id,
                    vector=embedding,
                    payload={
                        "question_id": new_qa.question_id,
                        "intent_id": intent_id,
                        "question_text": question_text,
                        "answer_text": answer_text,
                        "type": "training_qa"
                    }
                )
            ]
        )
        
        return {
            "postgre_question_id": new_qa.question_id,
            "qdrant_question_id": point_id
        }
    
    

    def search_documents(self, query: str, top_k: int = 5):
        """
        Search documents (Fallback)
        
        Fallback path: TÃ¬m document chunks khi training Q&A khÃ´ng match
        - Query â†’ Embed â†’ Search documents collection
        - Return top_k chunks
        - LLM sáº½ synthesize answer tá»« chunks
        
        Args:
            query: User question
            top_k: Sá»‘ chunks (lower score â†’ fallback)
        
        Returns:
            List of document chunks
        """
        
        query_embedding = self.embeddings.embed_query(query)
        
        results = self.qdrant_client.search(
            collection_name=self.documents_collection,
            query_vector=query_embedding,
            limit=top_k
        )
        
        return results
    
    def search_training_qa(self, query: str, top_k: int = 5):
        """
        Search training Q&A (Priority 1)
        
        Fast path: TÃ¬m pre-approved answers
        - Query â†’ Embed â†’ Search training_qa collection
        - Return top_k matches
        - filter score > 0.8
        
        Args:
            query: User question
            top_k: Sá»‘ results (default 5)
        
        Returns:
            List of search results with scores
        """
        
        query_embedding = self.embeddings.embed_query(query)
        
        results = self.qdrant_client.search(
            collection_name=self.training_qa_collection,
            query_vector=query_embedding,
            limit=top_k
        )
        
        return results
    def hybrid_search(self, query: str):
        """
        Hybrid RAG Search Strategy
        
        PRIORITY SYSTEM (Cascade):
        1. TIER 1 - Training Q&A (score > 0.8)
           - Highest confidence, direct answer
           - No LLM needed, fast response
           
        2. TIER 2 - Training Q&A (0.7 < score <= 0.8)
           - Good match but not perfect
           - Use as primary answer + add document context
           
        3. TIER 3 - Document Search + LLM Generation
           - No training Q&A match
           - Search documents, LLM synthesize
           - Lower confidence, show sources
           
        4. TIER 4 - Fallback
           - Nothing found
           - Suggest live chat with officer
        
        Returns:
            {
                "response": str,
                "response_source": "training_qa" | "document" | "fallback",
                "confidence": float,
                "top_match": obj,
                "intent_id": int,
                "sources": list
            }
        """
        
        # STEP 1: Search training Q&A
        qa_results = self.search_training_qa(query, top_k=3)
        print("answer: ")
        print(qa_results[0].score)
        # TIER 1: Perfect match (score > 0.7)
        if qa_results and qa_results[0].score > 0.7:
            top_match = qa_results[0]
            return {
                "response_official_answer": top_match.payload.get("answer_text"),
                "response_source": "training_qa",
                "confidence": top_match.score,
                "top_match": top_match,
                "intent_id": top_match.payload.get("intent_id"),
                "question_id": top_match.payload.get("question_id"),
                "sources": []
            }
        
        
        # TIER 2: No training Q&A match, try documents
        doc_results = self.search_documents(query, top_k=5)
        print("score document:")
        print(doc_results[0].score)
        if doc_results and len(doc_results) > 0: 
            return {
                    "response": doc_results,
                    "response_source": "document",
                    "confidence": doc_results[0].score,
                    "top_match": doc_results[0],
                    "intent_id": doc_results[0].payload.get("intent_id"),
                    "sources": [r.payload.get("document_id") for r in doc_results]
                }
        else:
            return {
                "response": doc_results,
                "response_source": "document",
                "confidence": 0.0,
                "top_match": None,
                "intent_id": 0,
                "sources": []
            }
        
    def _get_user_personality_and_academics(self, user_id: int, db: Session) -> Dict[str, Any]:
        out = {
            "personality_summary": None,
            "riasec": None,
            "academic_summary": None,
            "gpa": None,
            "subjects": {}
        }

        # --- RIASEC result ---
        ri = (
            db.query(RiasecResult)
            .filter(RiasecResult.customer_id == user_id)
            .order_by(RiasecResult.result_id.desc())
            .first()
        )

        if ri:
            out["riasec"] = {
                "R": ri.score_realistic,
                "I": ri.score_investigative,
                "A": ri.score_artistic,
                "S": ri.score_social,
                "E": ri.score_enterprising,
                "C": ri.score_conventional,
            }
            # `result` field = summary cá»§a báº¡n
            out["personality_summary"] = ri.result or self._riasec_to_summary(out["riasec"])

        # --- Academic scores ---
        score = (
            db.query(AcademicScore)
            .filter(AcademicScore.customer_id == user_id)
            .first()
        )

        if score:
            subj_map = {
            "math": score.math,
            "literature": score.literature,
            "english": score.english,
            "physics": score.physics,
            "chemistry": score.chemistry,
            "biology": score.biology,
            "history": score.history,
            "geography": score.geography,
        }

            # simple GPA = average score
            valid_scores = [v for v in subj_map.values() if v is not None]
            gpa = round(sum(valid_scores) / len(valid_scores), 2)

            out["subjects"] = subj_map
            out["gpa"] = gpa
            out["academic_summary"] = (
                f"GPA xáº¥p xá»‰ {gpa}. CÃ¡c mÃ´n: " +
                ", ".join([f"{k}: {v}" for k, v in subj_map.items()])
            )
            print(out["academic_summary"])
        return out

    def _riasec_to_summary(self, ri_map: Dict[str,int]) -> str:
        # very small helper - báº¡n cÃ³ thá»ƒ má»Ÿ rá»™ng
        order = sorted(ri_map.items(), key=lambda x: -x[1])
        top = order[0][0] if order else None
        return f"Æ¯u tháº¿ RIASEC: {', '.join([f'{k}={v}' for k,v in ri_map.items()])}. ChÃ­nh: {top}."

    def _get_all_majors_from_db(self, db: Session, limit: int = 200) -> List[Dict[str,Any]]:
        """
        Láº¥y danh sÃ¡ch majors
        """
        rows = db.query(Major).order_by(Major.major_name).limit(limit).all()
        majors = []
        for r in rows:
            majors.append({
                "major_id": r.major_id,
                "major_name": r.major_name,
            })
        return majors

    def _get_all_majors_and_specialization_from_db(self, db: Session, limit: int = 200) -> List[Dict[str, Any]]:
        """
        Láº¥y danh sÃ¡ch majors kÃ¨m theo danh sÃ¡ch specializations
        """
        rows = (
            db.query(Major)
            .order_by(Major.major_name)
            .limit(limit)
            .all()
        )

        majors = []
        for r in rows:
            majors.append({
                "major_id": r.major_id,
                "major_name": r.major_name,
                "specializations": [
                    {
                        "specialization_id": s.specialization_id,
                        "specialization_name": s.specialization_name
                    }
                    for s in r.specializations
                ]
            })

        return majors
    
    

    

langchain_service = TrainingService()
